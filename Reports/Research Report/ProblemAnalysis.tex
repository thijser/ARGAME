\chapter{Problem Analysis} \label{cha:analysis}
	% Includes the challenges surrounding AR and Networking.
	% Also motivates the choices made.
	This chapter provides an analysis of the problem description of problems
	and challenges that may arise during development. It provides an analysis
	of the problems and possible solutions that can be used in order to
	solve these problems.

	One of the core challenges of the project is the use of Augmented Reality
	(AR) technology. An analysis of the available options to implement this
	functionality is given in section \ref{sec:ar}. Another important challenge
	is improving situational awareness, which is discussed in section
	\ref{sec:awareness}. The last challenge is the creation of interdependence
	between players in such a way that requires collaboration from all players.
	This challenge is analyzed in section \ref{sec:interdependence}.

	Lastly, a conclusion based on the analyses of these challenges is given in
	section \ref{sec:analysisconclusion}.

	\section{Augmented Reality (AR) Functionality} \label{sec:ar}
		% AR is a core element in the project. As such, we need to compare
		% various AR hardware devices and corresponding ways to implement
		% AR functionality for each device.
		Augmented Reality (AR) is a core aspect of the problem formulation.
		As such, careful analysis has to be done as to how the AR functionality
		can be best implemented to fully address the context of this project.

		We consider two choices for implementing AR functionality: The META One,
		an optical see-through device (\ref{ssec:metaone}), and the Oculus Rift
		Virtual Reality glasses in conjunction with mounted cameras
		(\ref{ssec:oculusrift}).

		% Hardware devices to consider:
		\subsection{META One} \label{ssec:metaone}
			%   - META One (as indicated by the BEPSys project page)
			%       - Has a limited Field-of-View (around 35 degrees)
			%          - May interfere with the experience of the game.
			%       - Optical see-through glasses means AR works out of the box.

			The META One glasses are optical see-through glasses. Optical
			see-through glasses work by projecting a virtual image on top of the
			world you see, effectively implementing a 3D AR exprience.

			Because the META One is an optical see-through device that also
			features motion tracking, AR can be implemented simply by
			projecting an image against a black background to the glasses.

			A big drawback of the available META One glasses is their
			Field-of-View, which is 35 degrees. This Field-of-View is way lower
			than the Field-of-View of a person, which may have a negative impact
			on the game experience.

		\subsection{Oculus Rift} \label{ssec:oculusrift}
			%   - Oculus Rift + mounted cameras (http://oculusvr.com/)
			%       - High Field-of-View (100 degrees)
			%       - VR glasses, so need to project the real world using cameras.
			%          - Limited resolution creates blurriness.
			%          - Projection can be done from within Unity
			%          - Potentially requires a lot of calibration
			% 		- Using Oculus Rift means we need to implement AR functionality
			%         ourselves (as optical see-through often has this built-in).
			%         AR Libraries to consider:
			We've built a camera rig for the Oculus Rift that can be used to
			turn it into an augmented reality device. To detect the markers and
			render objects on them in Unity, there are several libraries
			available. Each of these will be discussed in the next sections.

			Oculus offers an SDK for Unity that makes it easy to integrate a
			game with the Rift. The challenge that we'll be facing during
			development is to properly integrate this SDK with the augmented
			reality libraries. Each of the frameworks try to take control of the
			camera in different ways and it's easy to get conflicts there.
			Getting the Rift see-through functionality working in Unity on its
			own and the augmented reality functionality on its own is not a
			challenge.

			\subsubsection{Vuforia} \label{sssec:vuforia}
				%   - Vuforia (http://vuforia.com/ and http://developer.vuforia.com/)
				%       - Includes integration with Unity
				Vuforia is a framework by Qualcomm that allows you to create
				arbitrary markers, import them into Unity and place objects onto
				them. You can then select a webcam and have it render the camera
				images with 3D objects projected onto the markers. It's very
				easy to use and has built-in support for virtual reality
				solutions like GearVR. The tracking quality is very good and
				stable, even with low quality markers (with few color transitions).

				Unfortunately it currently only works with the 32-bit version of
				Unity. It also lacks support for the Oculus Rift on the desktop,
				which means that we'll have to build that functionality ourselves.

			\subsubsection{Unity AR Toolkit (UART)} \label{sssec:uart}
				%   - Unity AR Toolkit (UART) (https://research.cc.gatech.edu/uart/content/contents/)
				%       - Source code and demos hosted on SourceForge (http://sourceforge.net/projects/uart/)
				%       - Seems to be a research project
				%       - Seems easy to use (comes with examples)
				%       - Built for Unity
				%       - Last change to SVN repo was in 2011.


			\subsubsection{Metaio} \label{sssec:metaio}
				%   - Metaio (http://www.metaio.com/)
				%       - Mainly oriented towards mobile phones, so may not be suitable for this project

		%   - ... <Add more as needed>

	\section{Situational Awareness} \label{sec:awareness}
		% Improving situational awareness is part of the main goal of the project.
		% We should indicate the steps needed to achieve this, which can be based
		% on (possibly) a large range of scientific articles.
		This project is about exploring the different perception of situational
		awareness, presence and workload in a physical and an AR environment
		(see chapter \ref{cha:problem}). As such, situational awareness plays a
		key role in this project.

		Before considering how situational awareness plays a role in this project,
		it is important to define exactly what situational awareness means.
		According to \cite{endsley}, situational awareness is defined as "the
		perception of the elements in the environment within a volume of time and
		space, comprehension of their meaning, and the projection of their status in
		the near future". In other words, situational awareness means to
		fully understand the situation, and be able to predict what is going to
		happen next. This also includes understanding any risks the situation brings.


	\section{Interdependence between players} \label{sec:interdependence}
		% Creating interdependence between players requires them to work together.
		% This can be done in several ways. We need to elaborate on the various ways
		% in which this can be achieved.
		The problem formulation states that the game is to be employed as an
		approximation of collaboratively solving complex problems. In order to
		motivate players of the game to collaborate, there is a need to create
		a form of interdependence amongst the players. One way to do this is to
		create an asymmetry between either the information that the players have or
		an asymmetry of abilities, as explained in the following subsection. 
		\subsection{Asymmetry of abilities}
			The main reason to co-operate is the asymmetry of abilities between
			the players involved. For example: physically co-located players can
			alter the game world, while virtually co-located players can guide
			characters to a certain goal utilizing the altered game environment.
			One thing to note is that a "puppet master" scenario should be avoided.
			This scenario happens when one player can do everything except for a
			few required tasks, and uses the other players to execute these tasks.
			In this case, the other players will have less involvement with the
			shared goal, and the amount of co-operation will go down.
		\subsection{Asymmetry of information}
			Asymmetry of information could be used as another reason for the players
			to co-operate. It means that both types of players (both the physically
			co-located and the virtually co-located) have different, separate, parts
			of the information required to complete the game. in this case, a 
			"puppet master" scenario should also be avoided. Such a scenario can occur
			here when one type of player has nearly all of the information or can
			infer nearly all information.
		
	\include{VirtualCoLocation.tex}
		Establishing virtual co-location is required to allow physically remote players
		to play the game together. As such, both the virtualization of the game world and
		the networking are considered in virtually co-locating physically remote players.
		Unity has multi player support, because of its master server to handle multi player
		games, but the server could be down at times. There are tutorials on the internet
		to create a basic multi player game that uses the master server to handle requests.
		These tutorials can be used to implement our own multilayer support. Alternatively
		we could provide the players with the means to easily get and exchange their IP
		addresses through other means such as mail. 
		Besides the networking we have to look at how we synchronize locations, depending on
		the chosen game we have in order of ascending complexity several options:
		1 Use markers with a known locations, this only works if we have a limited size 
		and reasonably fixed playing area which we can prepare ahead of time. This most 
		likely comes in the form of a set of markers at the edge and middle of the playing 
		field. 
		2 Use mobile markers which synchronize between players automatically, for example
		cards in a card game. This only works if we can trust the play er to keep these markers
		within their screen or if it does not matter if there is no augmentation needed if they
		cannot see a marker. 
		3 Object recognition which tracks the locations of objects in the scene,
		this method only works if there are a number of reasonably stable objects 
		within the player's vision. 
		4 Combining the output of a compass, a gyroscope and trilocations. This is 
		works regardless of what is visible but requires accurate trilocation which works
		can be quite hard to do without building a heavy rig. 
		Of course a combination of several of the above methods is also possible. 

		Then there is the matter of making the players "feel" that they are in the 
		same location. One obvious method might be to put an oculus on the remote player(s) and let 
		them see through the eyes of the local player(s), however this is likely to cause nausea. 
		Of course we can do away with the oculus but that might result in relative pasivism from 
		the remote players as they feel they cannot 
		even control their own view while not being forced to watch what the other player does. 

		We can also let the remote player control one or more avatars within the game world
		and view these through either oculus or screen. This would keep the remote player
		more interested by giving more of a feeling of agency then just viewing through the eyes 
		of the other player at the cost of the feeling of connectivity. But this would require 
		mapping out a large part of the scene in the virtual world. 
		
		Lastly we can also let the remote player view the world from a birds eye perspective 
		this can either be done by mounting a camera above the scene or by rendering it in 
		the virtual world, the second case offers increased player agency resulting in 
		a better attention to the situation at the cost of having the map the scene fully 
		in the virtual world. 
		
		% Allowing phsyically remote players to play the game, we need to establish
		% some idea of virtual co-location. This includes the virtualization of the
		% game world as well as the networking functionality required to establish
		% the actual connection.

	\section{Analysis Conclusions} \label{sec:analysisconclusion}
		\include{AnalysisConclusion.tex}
		% Provides the coices we made for the abovementioned problems along with a short
		% motivation based on the above analysis.
